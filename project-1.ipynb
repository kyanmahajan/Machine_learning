{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10618775,"sourceType":"datasetVersion","datasetId":6574594}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:06.436921Z","iopub.execute_input":"2025-02-18T18:50:06.437342Z","iopub.status.idle":"2025-02-18T18:50:06.449841Z","shell.execute_reply.started":"2025-02-18T18:50:06.437300Z","shell.execute_reply":"2025-02-18T18:50:06.448915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata = pd.read_csv('/kaggle/input/alzheimers-prediction-dataset-global/alzheimers_prediction_dataset.csv')\ndata.head()\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:06.453137Z","iopub.execute_input":"2025-02-18T18:50:06.453548Z","iopub.status.idle":"2025-02-18T18:50:06.786680Z","shell.execute_reply.started":"2025-02-18T18:50:06.453517Z","shell.execute_reply":"2025-02-18T18:50:06.785612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**DATA ANALYSIS**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\ncountry_counts = data['Country'].value_counts()\nunique_countries = data['Country'].unique().tolist()\n\nprint(country_counts)\nprint(unique_countries)\n\nsns.countplot(x=data['Genetic Risk Factor (APOE-ε4 allele)'], hue = data['Alzheimer’s Diagnosis'])\n\n    \n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:06.788140Z","iopub.execute_input":"2025-02-18T18:50:06.788522Z","iopub.status.idle":"2025-02-18T18:50:07.073440Z","shell.execute_reply.started":"2025-02-18T18:50:06.788491Z","shell.execute_reply":"2025-02-18T18:50:07.072334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The previous graph made it clear that if someone has genetic risk fastor its a higher chance that the person will get alzhimers","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\n\n\ncolumn_indices = [0, 2, 5, 6, 7]\n\n\nfor idx in column_indices:\n    column_name = data.columns[idx]  # Get the column name by index\n    sns.countplot(x=data[column_name], hue=data['Alzheimer’s Diagnosis'])\n    \n    # Set labels and title for clarity\n    plt.xlabel(column_name)\n    plt.title(f'Countplot of {column_name} vs Alzheimer’s Diagnosis')\n    \n    # Show the plot\n \n\n\n\n\n\n\nplt.show()\nfor country in unique_countries :\n    sns.displot(data[(data['Alzheimer’s Diagnosis'] == 'Yes') & (data['Country'] == country)]['Age'])\n    plt.xlabel(country)\n\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:07.075209Z","iopub.execute_input":"2025-02-18T18:50:07.075545Z","iopub.status.idle":"2025-02-18T18:50:14.343452Z","shell.execute_reply.started":"2025-02-18T18:50:07.075519Z","shell.execute_reply":"2025-02-18T18:50:14.341970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The previous analysis was meant to understand how the disease is varying country wise with age. And a very similar pattern was found with some outliers which can be ignored safely.\nThe main intention behind this was to know if the country have any significant effect on disease as varied with age.","metadata":{}},{"cell_type":"code","source":"sns.countplot(x=data['Diabetes'], hue=data['Alzheimer’s Diagnosis'])\nplt.show()\n\na = ((data['Alzheimer’s Diagnosis'] == 'Yes') & (data['Diabetes'] == 'Yes')).sum() / (data['Alzheimer’s Diagnosis'] == 'Yes').sum()\n#b= ((data['Alzheimer’s Diagnosis'] == 'Yes') & (data['Diabetes'] == 'No')).sum() / (data['Alzheimer’s Diagnosis'] == 'Yes').sum()\n\nprint(a)\nprint(b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:14.344951Z","iopub.execute_input":"2025-02-18T18:50:14.345243Z","iopub.status.idle":"2025-02-18T18:50:14.628702Z","shell.execute_reply.started":"2025-02-18T18:50:14.345219Z","shell.execute_reply":"2025-02-18T18:50:14.627709Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The previous part showed that having diabetes do no have much effect on the disease","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x=data['Alzheimer’s Diagnosis'], y=data['BMI'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:14.629745Z","iopub.execute_input":"2025-02-18T18:50:14.630085Z","iopub.status.idle":"2025-02-18T18:50:14.819139Z","shell.execute_reply.started":"2025-02-18T18:50:14.630057Z","shell.execute_reply":"2025-02-18T18:50:14.818214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.boxplot(x=data['Alzheimer’s Diagnosis'], y=data['Age'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:14.820098Z","iopub.execute_input":"2025-02-18T18:50:14.820382Z","iopub.status.idle":"2025-02-18T18:50:14.998568Z","shell.execute_reply.started":"2025-02-18T18:50:14.820360Z","shell.execute_reply":"2025-02-18T18:50:14.997565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(x= data['Gender'], hue=data['Alzheimer’s Diagnosis'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:14.999540Z","iopub.execute_input":"2025-02-18T18:50:14.999811Z","iopub.status.idle":"2025-02-18T18:50:15.255320Z","shell.execute_reply.started":"2025-02-18T18:50:14.999788Z","shell.execute_reply":"2025-02-18T18:50:15.254180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.boxplot(x=\"Alzheimer’s Diagnosis\", y=\"Age\", hue=\"Gender\", data=data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:15.258674Z","iopub.execute_input":"2025-02-18T18:50:15.258959Z","iopub.status.idle":"2025-02-18T18:50:15.607097Z","shell.execute_reply.started":"2025-02-18T18:50:15.258935Z","shell.execute_reply":"2025-02-18T18:50:15.606179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.countplot(x= data['Gender'], hue=data['Alzheimer’s Diagnosis'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:15.608575Z","iopub.execute_input":"2025-02-18T18:50:15.608872Z","iopub.status.idle":"2025-02-18T18:50:15.861188Z","shell.execute_reply.started":"2025-02-18T18:50:15.608847Z","shell.execute_reply":"2025-02-18T18:50:15.860046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The previous graphs showed that only age is a major factor in determining if a person have the disease or not.","metadata":{}},{"cell_type":"markdown","source":"**Feature engineering**","metadata":{}},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:15.862165Z","iopub.execute_input":"2025-02-18T18:50:15.862480Z","iopub.status.idle":"2025-02-18T18:50:15.919927Z","shell.execute_reply.started":"2025-02-18T18:50:15.862454Z","shell.execute_reply":"2025-02-18T18:50:15.918724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Apply Label Encoding to the categorical output (removing any trailing spaces)\ndata['Alzheimer’s Diagnosis'] = label_encoder.fit_transform(data['Alzheimer’s Diagnosis'].str.strip())\n\n# Check the mapping of original labels to encoded values\n\n\n# Define the order of categories\ncategories = [['Never', 'Occasionally', 'Regularly']]  # Define in increasing order\n\n# Initialize and fit OrdinalEncoder\nordinal_encoder = OrdinalEncoder(categories=categories)\n\n# Replace the existing 'Alcohol Consumption' column with its encoded values\ndata['Alcohol Consumption'] = ordinal_encoder.fit_transform(data[['Alcohol Consumption']])\n\n# Display first few rows\nprint(data.head())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:15.920897Z","iopub.execute_input":"2025-02-18T18:50:15.921296Z","iopub.status.idle":"2025-02-18T18:50:15.992410Z","shell.execute_reply.started":"2025-02-18T18:50:15.921238Z","shell.execute_reply":"2025-02-18T18:50:15.991146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categoriess = [['Low', 'Medium', 'High']]\n\nordinal_encoder = OrdinalEncoder(categories=categoriess)\n\n# Replace the existing 'Alcohol Consumption' column with its encoded values\n\ndata['Stress Levels'] = ordinal_encoder.fit_transform(data[['Stress Levels']])\n\n# Display first few rows\nprint(data.head())\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:15.993607Z","iopub.execute_input":"2025-02-18T18:50:15.993973Z","iopub.status.idle":"2025-02-18T18:50:16.034822Z","shell.execute_reply.started":"2025-02-18T18:50:15.993945Z","shell.execute_reply":"2025-02-18T18:50:16.033714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**MODEL TRAINING**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nimport numpy as np\n\n# Example data (replace with your actual data)\n# data = ...\n\nx = data.iloc[:, [1,3,4]]  # Select the 2nd and 4th columns for features\ny = data.iloc[:, [-1]]    # Select the last column for the target\n\n# Create classifiers\ncf1 = LogisticRegression()\ncf2 = KNeighborsClassifier()\ncf3 = RandomForestClassifier()\n\n# List of estimators\nesti = [('lr', cf1), ('knn', cf2), ('rfc', cf3)]\n\n# Cross-validation and printing results\nfor est in esti:\n    cv = cross_val_score(est[1], x, y.to_numpy().ravel(), cv=10, scoring='accuracy')\n    print(est[0], np.round(np.mean(cv), 2))\n\n\nfrom sklearn.ensemble import VotingClassifier\nvc=  VotingClassifier(estimators = esti, voting = 'hard')\nnv = cross_val_score(vc, x,y.to_numpy().ravel(),cv=10, scoring= 'accuracy')\n\nprint(nv)\n    \n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:53.017988Z","iopub.execute_input":"2025-02-18T18:50:53.018437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nv.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.046234Z","iopub.status.idle":"2025-02-18T18:50:16.046773Z","shell.execute_reply":"2025-02-18T18:50:16.046551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.048077Z","iopub.status.idle":"2025-02-18T18:50:16.048590Z","shell.execute_reply":"2025-02-18T18:50:16.048342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_new = data.iloc[:, [1,3,-6,-1]];\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n\n# Initialize LabelEncoder\n\nle = LabelEncoder();\ndata_new['Genetic Risk Factor (APOE-ε4 allele)'] = le.fit_transform(data_new['Genetic Risk Factor (APOE-ε4 allele)'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.049530Z","iopub.status.idle":"2025-02-18T18:50:16.049846Z","shell.execute_reply":"2025-02-18T18:50:16.049721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_new","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.050694Z","iopub.status.idle":"2025-02-18T18:50:16.051018Z","shell.execute_reply":"2025-02-18T18:50:16.050895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Assuming you have a dataframe `data` and the target column is 'Alzheimer’s Diagnosis'\n# For example, let's use a dataset like 'data' as a placeholder.\n# Replace 'data' with your actual dataset.\n\n# Example data loading (you can replace this with your actual data)\n# data = pd.read_csv('your_data.csv')  # Replace with your dataset loading method\n\n# Corrected sampling and column drop\nsampled_data = data_new.sample(400, replace=True)\nX = sampled_data.drop(columns=['Alzheimer’s Diagnosis'])\ny = sampled_data['Alzheimer’s Diagnosis']\n\n# Create a Decision Tree classifier\ndt = DecisionTreeClassifier()\n\n# Perform cross-validation (10-fold) and calculate accuracy\ncv_scores = cross_val_score(dt, X, y, cv=10, scoring='accuracy')\n\n# Print the mean accuracy\nprint(np.mean(cv_scores))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.051781Z","iopub.status.idle":"2025-02-18T18:50:16.052208Z","shell.execute_reply":"2025-02-18T18:50:16.052013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nbg = BaggingClassifier(\n     estimator=DecisionTreeClassifier(),\n    n_estimators=200,\n    max_samples=0.5,\n    bootstrap=True,\n    random_state=42\n);\n\ncvv= cross_val_score(bg, X, y, cv=10, scoring='accuracy')\n\nprint(np.mean(cvv))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.053522Z","iopub.status.idle":"2025-02-18T18:50:16.054058Z","shell.execute_reply":"2025-02-18T18:50:16.053837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Applied algorithm on two different variants of the data but the accuracy score turned out to be similar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:50:16.054831Z","iopub.status.idle":"2025-02-18T18:50:16.055184Z","shell.execute_reply":"2025-02-18T18:50:16.055030Z"}},"outputs":[],"execution_count":null}]}